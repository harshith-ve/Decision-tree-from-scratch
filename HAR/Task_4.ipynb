{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tsfel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from apikey import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API and Models \n",
    "Groq_Token = api_key  # Do not share this key with anyone\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 561)\n"
     ]
    }
   ],
   "source": [
    "X_train_featurised = pd.read_csv(\"./UCI HAR Dataset/train/X_train.txt\", sep='\\s+',header=None)\n",
    "y_train_featurised = pd.read_csv(\"./UCI HAR Dataset/train/y_train.txt\", sep='\\s+',header=None)\n",
    "\n",
    "print(X_train_featurised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 10\n",
    "offset = 100\n",
    "folders = [\"LAYING\",\"SITTING\",\"STANDING\",\"WALKING\",\"WALKING_DOWNSTAIRS\",\"WALKING_UPSTAIRS\"]\n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "combined_dir = os.path.join(\"Real Data\")\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "X_real_test = np.array(X_test)\n",
    "y_real_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='24'\n",
       "                  max='24',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  24\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = tsfel.get_features_by_domain() # retrieves all features\n",
    "X_real_test_featurised = tsfel.time_series_features_extractor(cfg, X_real_test, fs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 825)\n",
      "(7352, 561)\n"
     ]
    }
   ],
   "source": [
    "print(X_real_test_featurised.shape)\n",
    "print(X_train_featurised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 7)\n",
      "(24, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=7)\n",
    "X_train_reduced_tsefl = pca.fit_transform(X_train_featurised)\n",
    "X_real_test_reduced = pca.fit_transform(X_real_test_featurised)\n",
    "print(X_train_reduced_tsefl.shape)\n",
    "print(X_real_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Activity for example 1: 2\n",
      "Predicted Activity for example 2: 2\n",
      "Predicted Activity for example 3: 1\n",
      "Predicted Activity for example 4: 2\n",
      "Predicted Activity for example 5: 2\n",
      "Predicted Activity for example 6: 1\n",
      "Predicted Activity for example 7: 1\n",
      "Predicted Activity for example 8: 2\n",
      "Predicted Activity for example 9: 2\n",
      "Predicted Activity for example 10: 2\n",
      "Predicted Activity for example 11: 1\n",
      "Predicted Activity for example 12: 1\n",
      "Predicted Activity for example 13: 1\n",
      "Predicted Activity for example 14: 1\n",
      "Predicted Activity for example 15: 1\n",
      "Predicted Activity for example 16: 1\n",
      "Predicted Activity for example 17: 1\n",
      "Predicted Activity for example 18: 1\n",
      "Predicted Activity for example 19: 1\n",
      "Predicted Activity for example 20: 1\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\" \n",
    "You are tasked with classifying human activities based on featurized accelerometer data. The activities include:\n",
    "- WALKING\n",
    "- WALKING_UPSTAIRS\n",
    "- WALKING_DOWNSTAIRS\n",
    "- SITTING\n",
    "- STANDING\n",
    "- LAYING\n",
    "\n",
    "Here are a few labeled examples of the feature vectors and their corresponding activities:\n",
    "\n",
    "Example 1:\n",
    "Feature Vector: {example_1_vector}\n",
    "Activity: {example_1_label}\n",
    "\n",
    "Example 2:\n",
    "Feature Vector: {example_2_vector}\n",
    "Activity: {example_2_label}\n",
    "\n",
    "Example 3:\n",
    "Feature Vector: {example_3_vector}\n",
    "Activity: {example_3_label}\n",
    "\n",
    "Now, given the following 495-feature vector representing an activity window, predict the most likely activity label:\n",
    "Feature Vector: {feature_vector}\n",
    "\n",
    "\n",
    "do not give code.\n",
    "do not give extra information.\n",
    "return predicted activity only.\n",
    "\"\"\"\n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "# Few-shot learning function\n",
    "def few_shot_classification(feature_vector, labeled_examples):\n",
    "    # Prepare the prompt using a few labeled examples\n",
    "    prompt = few_shot_prompt.format(\n",
    "        example_1_vector=labeled_examples[0][\"feature_vector\"],\n",
    "        example_1_label=labeled_examples[0][\"label\"],\n",
    "        example_2_vector=labeled_examples[1][\"feature_vector\"],\n",
    "        example_2_label=labeled_examples[1][\"label\"],\n",
    "        example_3_vector=labeled_examples[2][\"feature_vector\"],\n",
    "        example_3_label=labeled_examples[2][\"label\"],\n",
    "        feature_vector=feature_vector\n",
    "    )\n",
    "    \n",
    "    # Invoke the Groq LLM\n",
    "    predicted_label = llm.invoke(prompt)\n",
    "    return predicted_label\n",
    "\n",
    "# Example labeled data for few-shot learning\n",
    "labeled_examples = [\n",
    "    \n",
    "    {\"feature_vector\": X_train_reduced_tsefl[1].tolist(), \"label\": \"LAYING\"},\n",
    "    {\"feature_vector\": X_train_reduced_tsefl[2].tolist(), \"label\": \"STANDING\"},\n",
    "    {\"feature_vector\": X_train_reduced_tsefl[6].tolist(), \"label\": \"WALKING\"},\n",
    "    {\"feature_vector\": X_train_reduced_tsefl[16].tolist(), \"label\": \"WALKING_DOWNSTAIRS\"},\n",
    "    {\"feature_vector\": X_train_reduced_tsefl[0].tolist(), \"label\": \"WALKING_UPSTAIRS\"},\n",
    "    {\"feature_vector\": X_train_reduced_tsefl[9].tolist(), \"label\": \"SITTING\"},\n",
    "]\n",
    "predicted_activities = []\n",
    "for i in range(20):  # Predict for 30 examples\n",
    "    example_vector = X_real_test_reduced[i+3].tolist()  # Using different test examples\n",
    "    predicted_activity = few_shot_classification(example_vector, labeled_examples)\n",
    "    predicted_activities.append(classes[predicted_activity.content])\n",
    "    print(f\"Predicted Activity for example {i+1}: {classes[predicted_activity.content]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(predicted_activities)\n",
    "\n",
    "y_pred.shape\n",
    "accuracy = accuracy_score(y_real_test[:20], y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (16, 500, 5)\n",
      "Testing data shape:  (8, 500, 5)\n"
     ]
    }
   ],
   "source": [
    "seed = 4\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_real_test,y_real_test,test_size=0.3,random_state=seed,stratify=y_real_test)\n",
    "\n",
    "print(\"Training data shape: \",X_train.shape)\n",
    "print(\"Testing data shape: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='16'\n",
       "                  max='16',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  16\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='8'\n",
       "                  max='8',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  8\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = tsfel.get_features_by_domain() # retrieves all features\n",
    "X_real_train_featurised = tsfel.time_series_features_extractor(cfg, X_train, fs=50)\n",
    "X_real_test_featurised = tsfel.time_series_features_extractor(cfg, X_test, fs=50)\n",
    "X_train_reduced= pca.fit_transform(X_real_train_featurised)\n",
    "X_test_reduced = pca.fit_transform(X_real_test_featurised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Activity for example 1: 2\n",
      "Predicted Activity for example 2: 1\n",
      "Predicted Activity for example 3: 1\n",
      "Predicted Activity for example 4: 3\n",
      "Predicted Activity for example 5: 1\n",
      "Predicted Activity for example 6: 2\n",
      "Predicted Activity for example 7: 1\n",
      "Predicted Activity for example 8: 1\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\" \n",
    "You are tasked with classifying human activities based on featurized accelerometer data. The activities include:\n",
    "- WALKING\n",
    "- WALKING_UPSTAIRS\n",
    "- WALKING_DOWNSTAIRS\n",
    "- SITTING\n",
    "- STANDING\n",
    "- LAYING\n",
    "\n",
    "Here are a few labeled examples of the feature vectors and their corresponding activities:\n",
    "\n",
    "Example 1:\n",
    "Feature Vector: {example_1_vector}\n",
    "Activity: {example_1_label}\n",
    "\n",
    "Example 2:\n",
    "Feature Vector: {example_2_vector}\n",
    "Activity: {example_2_label}\n",
    "\n",
    "Example 3:\n",
    "Feature Vector: {example_3_vector}\n",
    "Activity: {example_3_label}\n",
    "\n",
    "Now, given the following 495-feature vector representing an activity window, predict the most likely activity label:\n",
    "Feature Vector: {feature_vector}\n",
    "\n",
    "\n",
    "do not give code.\n",
    "do not give extra information.\n",
    "return predicted activity only.\n",
    "\"\"\"\n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "# Few-shot learning function\n",
    "def few_shot_classification(feature_vector, labeled_examples):\n",
    "    # Prepare the prompt using a few labeled examples\n",
    "    prompt = few_shot_prompt.format(\n",
    "        example_1_vector=labeled_examples[0][\"feature_vector\"],\n",
    "        example_1_label=labeled_examples[0][\"label\"],\n",
    "        example_2_vector=labeled_examples[1][\"feature_vector\"],\n",
    "        example_2_label=labeled_examples[1][\"label\"],\n",
    "        example_3_vector=labeled_examples[2][\"feature_vector\"],\n",
    "        example_3_label=labeled_examples[2][\"label\"],\n",
    "        feature_vector=feature_vector\n",
    "    )\n",
    "    \n",
    "    # Invoke the Groq LLM\n",
    "    predicted_label = llm.invoke(prompt)\n",
    "    return predicted_label\n",
    "\n",
    "# Example labeled data for few-shot learning\n",
    "labeled_examples = [\n",
    "    \n",
    "    {\"feature_vector\": X_train_reduced[1].tolist(), \"label\": \"WALKING_UPSTAIRS\"},\n",
    "    {\"feature_vector\": X_train_reduced[2].tolist(), \"label\": \"SITTING\"},\n",
    "    {\"feature_vector\": X_train_reduced[6].tolist(), \"label\": \"WALKING\"},\n",
    "    {\"feature_vector\": X_train_reduced[14].tolist(), \"label\": \"LAYING\"},\n",
    "    {\"feature_vector\": X_train_reduced[0].tolist(), \"label\": \"STANDING\"},\n",
    "    {\"feature_vector\": X_train_reduced[9].tolist(), \"label\": \"WALKING\"},\n",
    "]\n",
    "predicted_activities = []\n",
    "for i in range(8):  # Predict for 30 examples\n",
    "    example_vector = X_test_reduced[i].tolist()  # Using different test examples\n",
    "    predicted_activity = few_shot_classification(example_vector, labeled_examples)\n",
    "    predicted_activities.append(classes[predicted_activity.content])\n",
    "    print(f\"Predicted Activity for example {i+1}: {classes[predicted_activity.content]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 4 2 6 1 1 5 6 1 4 5 3 4 6 3]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(predicted_activities)\n",
    "y_pred.shape\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
